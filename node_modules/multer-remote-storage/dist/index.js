"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  RemoteStorage: () => RemoteStorage,
  S3Client: () => import_client_s3.S3Client,
  Storage: () => import_storage.Storage,
  v2: () => import_cloudinary.v2
});
module.exports = __toCommonJS(src_exports);
var import_fs = require("fs");
var import_storage2 = require("@google-cloud/storage");
var import_lib_storage = require("@aws-sdk/lib-storage");
var import_client_s32 = require("@aws-sdk/client-s3");

// types/cloudinary.ts
var import_cloudinary = require("cloudinary");

// types/gcs.ts
var import_storage = require("@google-cloud/storage");

// types/s3.ts
var import_client_s3 = require("@aws-sdk/client-s3");

// src/index.ts
var CLOUDINARY = "CLOUDINARY";
var GOOGLE_CLOUD_SERVICES = "Storage";
var AWS_S3 = "S3Client";
var generateCloudinaryUploadOptions = ({ req, file, cb }, params, options) => {
  let output = {
    ...params
  };
  if (options) {
    if (options.chunk_size) output.chunk_size = options.chunk_size;
    if (options.public_id) {
      if (typeof options.public_id === "string") output.public_id = options.public_id;
      else if (typeof options.public_id === "function") output.public_id = options.public_id(req, file, cb);
    }
  }
  return output;
};
var generateCloudinaryResponse = (uploadResponse) => {
  return {
    etag: uploadResponse.etag,
    filename: uploadResponse.public_id,
    folder: uploadResponse.folder || null,
    height: uploadResponse.height,
    width: uploadResponse.width,
    path: uploadResponse.secure_url,
    signature: uploadResponse.signature,
    size: uploadResponse.bytes,
    timeCreated: uploadResponse.created_at,
    versionId: uploadResponse.version_id
  };
};
var generateGcsUploadOptions = ({ req, file, cb }, params, options) => {
  let output = [{
    ...params
  }, ""];
  if (options) {
    if (options.chunk_size) output[0].chunkSize = options.chunk_size;
    if (options.public_id) {
      if (typeof options.public_id === "string") output[1] = options.public_id;
      else if (typeof options.public_id === "function") output[1] = options.public_id(req, file, cb);
    }
  }
  if (!output[1]) output[1] = file.originalname;
  return output;
};
var generateGcsResponse = (uploadResponse, bucket, destFileName) => {
  return {
    bucket: uploadResponse?.metadata?.bucket,
    contentType: uploadResponse?.metadata?.contentType,
    etag: uploadResponse?.metadata?.etag,
    filename: destFileName,
    path: `https://storage.googleapis.com/${bucket}/${destFileName}`,
    size: uploadResponse?.metadata?.size && typeof uploadResponse.metadata.size === "string" ? parseInt(uploadResponse.metadata.size) : void 0,
    storageClass: uploadResponse?.metadata?.storageClass,
    timeCreated: uploadResponse?.metadata?.timeCreated
  };
};
var generateS3UploadOptions = ({ req, file, cb }, client, params, options) => {
  let output = {
    client,
    params: {
      ...params,
      Body: file.stream,
      ContentType: params.ContentType || determineContentTypeForS3(file.originalname),
      Key: params.Key || file.originalname
    }
  };
  if (params.Metadata) output.params.Metadata = params.Metadata;
  if (options) {
    output = { ...output, ...options };
    if (options.chunk_size) output.partSize = options.chunk_size;
    if (options.public_id) {
      if (typeof options.public_id === "string") output.params.Key = options.public_id;
      else if (typeof options.public_id === "function") output.params.Key = options.public_id(req, file, cb);
    }
  }
  return output;
};
var generateS3Response = (uploadResponse, options) => {
  return {
    bucket: uploadResponse.Bucket,
    contentType: options.params.ContentType,
    etag: uploadResponse.ETag,
    filename: uploadResponse.Key,
    metadata: options.params.Metadata,
    path: uploadResponse.Location,
    encryption: uploadResponse.ServerSideEncryption,
    versionId: uploadResponse.VersionId
  };
};
var determineContentTypeForS3 = (filename) => {
  const ext = filename.split(".").pop();
  let contentType = "application/octet-stream";
  if (ext === "txt") contentType = "text/plain";
  else if (ext === "css" || ext === "csv" || ext === "html") contentType = `text/${ext}`;
  else if (ext === "htm") contentType = "text/html";
  else if (ext === "ics") contentType = "text/calendar";
  else if (ext === "jpeg" || ext === "png" || ext === "gif" || ext === "apng" || ext === "avif" || ext === "bmp" || ext === "tiff" || ext === "webp") contentType = `image/${ext}`;
  else if (ext === "jpg") contentType = "image/jpeg";
  else if (ext === "ico") contentType = "image/vnd.microsoft.icon";
  else if (ext === "tif") contentType = "image/tiff";
  else if (ext === "svg") contentType = "image/svg+xml";
  else if (ext === "json" || ext === "pdf" || ext === "rtf" || ext === "zip") contentType = `application/${ext}`;
  else if (ext === "js" || ext === "mjs") contentType = "text/javascript";
  else if (ext === "avi") contentType = "video/x-msvideo";
  else if (ext === "mp4" || ext === "mpeg" || ext === "webm") contentType = `video/${ext}`;
  else if (ext === "ts") contentType = "video/mp2t";
  else if (ext === "aac" || ext === "midi" || ext === "opus" || ext === "wav") contentType = `audio/${ext}`;
  else if (ext === "mp3") contentType = "audio/mpeg";
  else if (ext === "rar") contentType = "application/vnd.rar";
  else if (ext === "ppt") contentType = "vnd.ms-powerpoint";
  else if (ext === "php") contentType = "application/x-httpd-php";
  else if (ext === "jar") contentType = "application/java-archive";
  else if (ext === "gz") contentType = "application/gzip";
  else if (ext === "doc") contentType = "application/msword";
  else if (ext === "docx") contentType = "application/vnd.openxmlformats-officedocument.wordprocessingml.document";
  return contentType;
};
var RemoteStorage = class {
  #client;
  #host;
  #params;
  #options;
  #validator;
  #trash;
  constructor(opts) {
    this.#params = opts.params || {};
    this.#options = opts.options || {};
    this.#validator = typeof this.#options.validator === "function" ? this.#options.validator : null;
    this.#trash = this.#options.trash || "trash.txt";
    switch (opts.target) {
      case CLOUDINARY:
        import_cloudinary.v2.config(opts.config);
        this.#client = import_cloudinary.v2;
        this.#host = CLOUDINARY;
        break;
      case "GCS":
        this.#client = new import_storage2.Storage(opts.config);
        this.#host = this.#client.constructor.name;
        break;
      case "AWS_S3":
        this.#client = new import_client_s32.S3Client(opts.config);
        this.#host = this.#client.constructor.name;
        break;
    }
    if (!this.#client) throw new Error("Must define a client for Cloudinary, Google Cloud Storage, or AWS S3");
  }
  getTarget() {
    let output;
    switch (this.#host) {
      case CLOUDINARY:
        output = "CLOUDINARY";
        break;
      case GOOGLE_CLOUD_SERVICES:
        output = "GCS";
        break;
      case AWS_S3:
        output = "AWS_S3";
        break;
      default:
    }
    return output;
  }
  _handleFile = async (req, file, cb) => {
    try {
      let validateSuccess = true;
      if (this.#validator) {
        validateSuccess = this.#validator(req, file, cb);
      }
      if (validateSuccess) {
        let res = null;
        const CONTENT_LENGTH = req.get("Content-Length");
        const SIZE = CONTENT_LENGTH ? parseInt(CONTENT_LENGTH) : 0;
        let complete = 0;
        file.stream.on("data", (data) => {
          complete += data.length;
          console.log(`Total: ${complete}`);
          console.log(`Complete: ${Math.floor(complete / SIZE * 100)}`);
        });
        res = await this.#upload(req, file, cb);
        cb(null, res);
      } else {
        file.stream.on("error", () => {
          console.log("STREAM ERROR");
        });
        const writeStream = (0, import_fs.createWriteStream)(this.#trash);
        file.stream.destroy();
        file.stream.pipe(writeStream);
        writeStream.end();
        (0, import_fs.rm)(this.#trash, (err) => {
        });
        return cb(null, {
          path: void 0,
          size: 0,
          filename: "/"
        });
      }
    } catch (err) {
      cb(err);
    }
  };
  _removeFile = (req, file, cb) => {
    switch (this.#host) {
      case CLOUDINARY:
        this.#client.uploader.destroy(
          file.filename,
          { invalidate: true },
          cb
        );
        break;
      case GOOGLE_CLOUD_SERVICES:
        this.#client.bucket(this.#params.bucket).file(file.filename).delete({ ignoreNotFound: true }, cb);
        break;
      case AWS_S3:
        this.#client.send(new import_client_s32.DeleteObjectCommand({
          Bucket: this.#params.Bucket,
          Key: file.filename
        }), cb);
        break;
      default:
    }
  };
  #upload = (req, file, cb) => {
    let params;
    switch (this.#host) {
      case CLOUDINARY:
        return new Promise((resolve, reject) => {
          params = this.#params;
          if (this.#options.chunk_size) {
            file.stream.pipe(this.#client.uploader.upload_chunked_stream(
              generateCloudinaryUploadOptions({ req, file, cb }, this.#params, this.#options),
              (err, uploadResponse) => {
                if (err) reject(err);
                if (uploadResponse) resolve(generateCloudinaryResponse(uploadResponse));
              }
            )).on("error", (err) => {
              console.log(err);
            });
          } else {
            file.stream.pipe(this.#client.uploader.upload_stream(
              generateCloudinaryUploadOptions({ req, file, cb }, this.#params, this.#options),
              (err, uploadResponse) => {
                if (err) reject(err);
                if (uploadResponse) resolve(generateCloudinaryResponse(uploadResponse));
              }
            )).on("error", (err) => {
              console.log(err);
            });
          }
        });
      case GOOGLE_CLOUD_SERVICES:
        return new Promise((resolve, reject) => {
          params = this.#params;
          const output = generateGcsUploadOptions({ req, file, cb }, params, this.#options);
          const [gcsUploadOptions, destFileName] = output;
          const bucket = this.#client.bucket(params.bucket);
          const destFile = bucket.file(destFileName);
          if (this.#options.chunk_size) {
            file.stream.pipe(
              destFile.createWriteStream(gcsUploadOptions)
            ).on("error", (err) => {
              destFile.delete({ ignoreNotFound: true });
              reject(err.message);
            }).on("finish", () => {
              params = this.#params;
              resolve(generateGcsResponse(destFile, params.bucket, destFileName));
            });
          } else {
            file.stream.pipe(
              destFile.createWriteStream(gcsUploadOptions)
            ).on("error", (err) => {
              destFile.delete({ ignoreNotFound: true });
              reject(err.message);
            }).on("finish", () => {
              params = this.#params;
              resolve(generateGcsResponse(destFile, params.bucket, destFileName));
            });
          }
        });
      case AWS_S3:
        return new Promise((resolve, reject) => {
          const s3Options = generateS3UploadOptions({ req, file, cb }, this.#client, this.#params, this.#options);
          const upload = new import_lib_storage.Upload(s3Options);
          try {
            upload.done().then((response) => {
              resolve(generateS3Response(response, s3Options));
            }).catch((err) => {
              reject(err);
            });
          } catch (err) {
            reject(err);
          }
        });
      default:
    }
  };
  delete = async (file, options) => {
    try {
      switch (this.#host) {
        case CLOUDINARY:
          if (options) {
            await this.#client.uploader.destroy(file, options);
          } else {
            await this.#client.uploader.destroy(file);
          }
          break;
        case GOOGLE_CLOUD_SERVICES:
          if (options) {
            await this.#client.bucket(this.#params.bucket).file(file).delete(options);
          } else {
            await this.#client.bucket(this.#params.bucket).file(file).delete();
          }
          break;
        case AWS_S3:
          if (options) {
            await this.#client.send(new import_client_s32.DeleteObjectCommand({
              Bucket: this.#params.Bucket,
              Key: file
            }));
          } else {
            if (options) {
              await this.#client.send(new import_client_s32.DeleteObjectCommand({
                ...options,
                Bucket: this.#params.Bucket,
                Key: file
              }));
            } else {
              await this.#client.send(new import_client_s32.DeleteObjectCommand({
                Bucket: this.#params.Bucket,
                Key: file
              }));
            }
          }
          break;
        default:
      }
    } catch (err) {
      if (err instanceof Error) console.error(err.message);
    }
  };
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  RemoteStorage,
  S3Client,
  Storage,
  v2
});
